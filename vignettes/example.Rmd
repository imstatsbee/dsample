---
title: "example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{example}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: references.bib
nocite: | 
    @Wang2014, @Wang2007
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(dsample)
```

## Simulation 

This example is taken from the study of @West1993. 

```{r}
expr <- expression((x1*(1-x2))^5 * (x2*(1-x1))^3 * (1-x1*(1-x2)-x2*(1-x1))^37)
sets <- list(x1=runif(1e4), x2=runif(1e4))
smp <- dsample(expr=expr, rpmat=sets, nk=3e3, n=3e2)
op <- summary(smp, n=10, k=2)
op$means
op$modes
do.call(cbind, lapply(split(op$X, op$grp), colMeans))
plot(op, which=2)
```

@Liang2007

```{r}
expr <- expression(
  1/3*mnormt::dmnorm(x=cbind(x1,x2), 
                     mean=c(-8,-8), 
                     varcov=matrix(c(1,0.9,0.9,1), ncol=2)) 
  + 1/3*mnormt::dmnorm(x=cbind(x1,x2), 
                       mean=c(6,6), 
                       varcov=matrix(c(1,-0.9,-0.9,1), ncol=2)) 
  + 1/3*mnormt::dmnorm(x=cbind(x1,x2), 
                       mean=c(0,0), 
                       varcov=matrix(c(1,0,0,1), ncol=2)))
sets <- list(x1=runif(n=1e4, min=-12, max=11), 
             x2=runif(n=1e4, min=-12, max=11))
y <- eval(expr=expr, env=sets)
smp <- dsample(expr=expr, rpmat=sets, nk=3e3, n=5e2)
op <- summary(smp, k=3)
op$means
op$modes
do.call(cbind, lapply(split(op$X, op$grp), colMeans))
plot(op, which=2)
```

## 6.1 Space Shuttle Challenger disaster 

@Dalal1989

Bayesian logistic regression 

```{r eval=FALSE}
failure <- c( 1, 1, 1,  1, 0, 0, 0,  0, 0, 0, 0,  0, 1, 1, 0,  0, 0, 1, 0,  0, 0, 0, 0);
temp <- c( 53, 57, 58, 63, 66, 67, 67, 67, 68, 69, 70, 70, 70, 70, 72, 73, 75, 75, 76, 76, 78, 79, 81);
data <- data.frame(temp=temp, failure=failure);
nrow(data)
data

y <- failure
x <- temp
N <- 23 

summary(f.b1 <- glm(y~x, family=binomial))
summary(f.b2 <- glm(y~x, family=binomial(link=cloglog)))


## https://is.muni.cz/el/sci/jaro2013/M8BDA/um/Lecture_1_-_9_-_Bayesian_Statistics_with_R_and_BUGS_2013.pdf?lang=en
## https://rstudio-pubs-static.s3.amazonaws.com/159664_1a1fbed2873049fc825eef4332a9b557.html
## https://www.stat.ubc.ca/~bouchard/courses/stat520-sp2014-15/lecture/2015/02/27/notes-lecture3.html

```

## 6.2 Beetle 

@Prentice1976

```{r eval=FALSE}
# Example : Generalized Logit Model - Dose-Response Dataset by Bliss(1935)
# Paper : Bayes and Empirical Bayes Methods for Data Analysis,Carlin and Louis,p. 177
# Type : Fu-Wang Algorithm

# Dose-Response Dataset by Bliss(1935), from Carlin and Louis, p.177
wi <- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839);
yi <- c(6, 13, 18, 28, 52, 53, 61, 60);
ni <- c(59, 60, 62, 56, 63, 59, 62, 60);
data <- data.frame(wi=wi, yi=yi, ni=ni);
```

## 6.3 Dugong

@Ratkowsky1986

Volume 2 in WinBUGS / nonconjugate nonlinear model 

```{r eval=FALSE}
# Example : Dugongs Data Analysis, Ratkowsky, 1983
# Paper : OPENBUGS, Carlin and Gelfand, 1991, p.125, Malefaki and Iliopoulos, 2008, p.1219
# Type : Wang-Lee Algorithm, Unbounded Case, Bayesian Analysis
# 
# Data set from Ratkowsky, 1983
x.age <- c( 1.0, 1.5, 1.5, 1.5, 2.5, 4.0, 5.0, 5.0, 7.0, 8.0, 8.5, 9.0, 9.5, 9.5, 10.0, 12.0, 12.0, 13.0, 13.0, 14.5, 15.5, 15.5, 16.5, 17.0, 22.5, 29.0, 31.5);
y.length <- c(1.80, 1.85, 1.87, 1.77, 2.02, 2.27, 2.15, 2.26, 2.35, 2.47, 2.19, 2.26, 2.40, 2.39, 2.41, 2.50, 2.32, 2.43, 2.47, 2.56, 2.65, 2.47, 2.64, 2.56, 2.70, 2.72, 2.57);
data <- data.frame(x.age=x.age, y.length=y.length);

```

## 6.4 British Coal Mining Data 

@Diggle1988

```{r eval=FALSE}
# https://search.r-project.org/CRAN/refmans/aspline/html/coal.html
# https://mysite.science.uottawa.ca/malvo/Mat4376-5313/Sample%20project%20R%20code.pdf
# Example : British Coalmining Disaster Data from 1851-1962
# Paper : Poisson change point model, Tanner 1992
# Type : Fu-Wang Algorithm
# 
# British Coalmining Disaster Data from 1851 -- 1962
x <- c(4, 5, 4, 1, 0, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6, 3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5, 2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3, 0, 0, 1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1);

```


## 6.5 Nuclear Pump Data 

@Gaver1987

```{r eval=FALSE}
# https://amath.colorado.edu/faculty/vdukic/Bayes/code/Gibbs_pumps_posted.R
# http://www.people.vcu.edu/~dbandyop/pubh7440/Example0.2015.pdf
# https://people.math.aau.dk/~slb/kurser/r-11/mini.pdf
# https://search.r-project.org/CRAN/refmans/bang/html/pump.html
# Example : Nuclear Pump Failure Rate, Poisson Empirical Bayesian Model
# Paper : Simulation and Monte Carlo with Applications in Finance and MCMC, J.S. Dagpunar, p.168
# Type : Wang-Lee Algorithm, Unbounded Case

# Nuclear Pump Failure Rate, Gaver and O'Muircheartaigh, 1987
time <- c(94.32, 15.72, 62.88, 125.76, 5.24, 31.44, 1.05, 1.05, 2.10, 10.48);
failure <- c( 5, 1, 5, 14, 3, 19, 1, 1, 4, 22);
data <- data.frame(time=time, failure=failure);
```


## 6.6 SLC 190 Genetic 

@Roeder1994

```{r eval=FALSE}
# Example : Genetic SLC190 Data Analysis
# Paper : A Practical Sampling Approach for a Bayesian Mixture Model with unknown number of components, Wang & Fu 2007
# Type : Wang-Lee Algorithm, Unbounded Case, Weight on the last partition  = 0.01

# Genetic SLC190 dataset
y<- c( 0.467, 0.451, 0.423, 0.412, 0.623, 0.43, 0.237, 0.534, 0.218, 0.199, 
 0.192, 0.313, 0.393, 0.304, 0.215, 0.192, 0.136, 0.273, 0.261, 0.321, 0.293, 
 0.245, 0.149, 0.206, 0.273, 0.16, 0.391, 0.225, 0.231,  0.259, 0.164, 0.349, 
 0.159, 0.182, 0.206, 0.126, 0.158, 0.17, 0.267, 0.376, 0.328, 0.252, 0.329, 
 0.198, 0.228, 0.202, 0.416, 0.183, 0.191, 0.155, 0.282, 0.232, 0.262, 0.258, 
 0.186, 0.328, 0.183, 0.25, 0.179, 0.097, 0.247, 0.254, 0.179, 0.197, 0.179, 
 0.132, 0.195, 0.329, 0.188, 0.174, 0.138, 0.141, 0.253, 0.202, 0.386, 0.224, 
 0.151, 0.27, 0.15, 0.393, 0.512, 0.073, 0.31, 0.201, 0.198, 0.221, 0.3, 0.321, 
 0.255, 0.243, 0.252, 0.231, 0.333, 0.293, 0.326, 0.193, 0.075, 0.284, 0.255, 
 0.25, 0.263, 0.208, 0.38, 0.189, 0.59, 0.186, 0.267, 0.222, 0.414, 0.461, 0.346, 
 0.187, 0.178, 0.292, 0.361, 0.219, 0.244, 0.265, 0.253, 0.321, 0.177, 0.245, 
 0.289, 0.168, 0.236, 0.349, 0.231, 0.199, 0.295, 0.139, 0.272, 0.167, 0.309, 
 0.215, 0.316, 0.245, 0.337, 0.279, 0.213, 0.313, 0.213, 0.251, 0.194, 0.267, 
 0.263, 0.197, 0.209, 0.203,  0.216, 0.18, 0.229, 0.181, 0.139, 0.264, 0.184, 
 0.245, 0.411, 0.162, 0.138, 0.354, 0.21, 0.191, 0.251, 0.239, 0.264, 0.281, 
 0.288, 0.619, 0.288, 0.269, 0.175, 0.28, 0.343, 0.311, 0.171, 0.273, 0.119, 
0.155, 0.414, 0.359, 0.439, 0.394, 0.34, 0.462, 0.338, 0.471, 0.443, 0.332, 
0.361, 0.163);

```
